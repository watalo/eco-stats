# 第4章 一元线性回归

## 4.1 一元线性回归模型
从总体中抽取n个样本，一元线性回归模型如下：
$$y_i=\alpha + \beta x_i + \epsilon_i \quad(i=1，\dots，n)$$
- $n$：样本容量
- $\alpha + \beta x_i$：总体回归线(population regression line) / 总体回归函数(population regression function，**PRF**) 

> 模型本身也被称为数据生产过程(Data Generation Process，**DGP**)

## 4.2 OLS估计量的推导
- 任务
	- 根据观测值 $\{x_i,y_i \}_{i=1}^n$ 来估计总体回归线（PRL）。
- 核心思路
	- 找到一条直线，让它离所有观测值最近。
		- 给定一条直线：$\hat y_i=\hat\alpha + \hat\beta x_i$
		- 计算观测值与直线的距离，：$e_i \equiv y_i - \hat\alpha - \hat\beta x_i$
			- 观测值与估计量的差，就是残差（Residual）
		- 当残差平方和最小时，直线离所有观测值最近。
- 实现方法
	- OLS，最小二乘法(ordinary least squares)
		- 选择 $\hat\alpha$ 和 $\hat\beta$，使残差平方和最小。
- 推导过程
	- 见Page64

> 残差平方和：sum of squared residuals（**SSR**） / residuals squared sum（**RSS**）

## 4.3 OLS的正交性




## 4.4 平方和分解公式

## 4.5 拟合优度

## 4.6 无常数项的回归

## 4.7 一元线性回归的python命令及实例

## 4.8 Stata命令运行结果的存储与调用
略

## 4.9 总体回归函数与样本回归函数：蒙特卡洛模拟
