# 第13章 平稳时间序列


>**平稳序列**
>具有以下特点：
>
>1. 均值（期望值）不变：序列中任意时刻的均值都是相同的，不随时间变化。
>2. 方差不变：序列中任意时刻的方差也是相同的，不随时间变化。
>3. 自相关函数（自协方差函数）不随时间平移而改变：序列中任意两个时间点的自相关（自协方差）只与这两个时间点之间的时间差有关，而与具体的起始时间无关。
>
>平稳序列可以进一步分为严格平稳序列和宽平稳序列：
>- 严格平稳序列（Strictly Stationary）：如果一个序列的所有阶矩（如均值、方差、偏度、峰度等）都不随时间变化，那么这个序列就是严格平稳的。
>- 宽平稳序列（Weakly Stationary）：如果一个序列的均值和方差不随时间变化，且自相关函数不随时间平移而改变，那么这个序列就是宽平稳的。
>
>在实际应用中，宽平稳序列的概念更常用，因为很多时间序列虽然不是严格平稳的，但它们的一阶和二阶矩（均值和方差）是平稳的，这在一定程度上满足了分析的需求。
## 13.1 时间序列的自相关

#定义  k阶自协方差
autocovanriance of oder k
$$\gamma_k\equiv Cov(y_t,y_{t-k})=E[(y_t-\mu)(y_{t-K}-\mu)]$$
- $\mu$ 为总体均值（$E(y)$）
- 反映了同一变量相隔k期之间的自相关程度
- $k=0$ 时，$\gamma_0=Var(y)$
- 估计值为样本自协方差：$$\hat\gamma_k \equiv = \frac{1}{T-k}\sum_{t=1}^{T-k}(y_t-\overline y)(y_{t+k}-\overline y)$$
#定义 k阶自相关系数
autocorrelation of oder k
$$\rho_k \equiv \frac{Cov(y_t,y_{t+k})}{Var(y_t)}$$
- 自相关系数是自协方差的标准化，取值范围[-1,1]
- 估计值为 $$\hat\rho_k \equiv \frac{\hat\gamma_k}{\hat\gamma_0}$$
	- 其中$\hat\rho_0 \equiv \frac{1}{T-1}\sum_{i=1}^T (y_t-\overline y)^2$ 为样本方差

$\rho_k$ 不依赖于具体时间，仅是滞后阶数k的函数，称为<span style="color:#00b0f0">自相关函数（Auto-correlation function，ACF）</span>

（k，$\rho_k$）画出图，称为<span style="color:#00b0f0">自相关图（correlogram）</span>

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import seaborn as sns

data = pd.read_stata('../2_Data/Data-2e/gdp_china.dta')
data['lny'] = np.log(data['y'])
data['dlny']  = data['lny'].diff().dropna()
data['dy'] = (data['y'] - data['y'].shift(1))/data['y'].shift(1)
data.set_index('year', inplace=True)
data.dropna(inplace=True)  

# 时间序列的趋势图
fig = plt.figure(figsize=(8,4))
sns.lineplot(x='year', y='y', data=data)

# 对数时间序列的趋势图
fig = plt.figure(figsize=(8,4))
sns.lineplot(x='year', y='lny', data=data)

# 对比
fig = plt.figure(figsize=(10,4))
sns.lineplot(x='year', y='dlny', data=data)
sns.lineplot(x='year', y='dy', data=data)

# ACF图和PACF图
from cq import acfgram

ac = acfgram(data['dlny'],lags=15)
```
### 自相关图函数

```python
import pandas as pd
import numpy as np
import statsmodels.api as sm
import seaborn as sns
import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

def acfgram(time_series,lags=10):
    '''acgram 绘制时间序列的自相关图和偏自相关图,并返回acf和pacf的结果
        达到类似与其他统计软件一样的效果
    Arguments:
        time_series -- pd.Series,array-like, 时间序列
    Keyword Arguments:
        lags -- int, 最大滞后阶数 (default: {10})
    Returns:
        1.plot:绘制时间序列的序列图、acf图和pacf图
        2.dataframe:返回字段命为lags acf pacf Q和Prob(Q)的数据
            - Q、Prob(Q) -- acf的统计量
    '''

    # 计算自相关系数
    acf_result = sm.tsa.acf(time_series,
                            nlags = lags,
                            qstat=True,
                            fft=False)

    # 计算偏自相关系数
    pacf_result = sm.tsa.pacf(time_series, nlags=lags)
    # 创建DataFrame来存储结果

    result_df = pd.DataFrame({
        'Lags': np.arange(1,lags+1),
        'ACF': acf_result[0][1:],
        'PACF': pacf_result[1:],
        'Q':acf_result[1],
        'Prob(Q)': acf_result[2]  
    })

    # 绘制自相关图
    _, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 15), dpi=400)
    ## 分别画出3个图
    time_series.plot(ax=axes[0])
    plot_acf(time_series, lags=lags,ax=axes[1])
    plot_pacf(time_series,lags=lags,ax=axes[2])
    ## 设置图标题
    axes[0].set_title('Time-Series')
    axes[1].set_title('Autocorrelation')
    axes[2].set_title('Partial-Autocorrelation')
    plt.show()

    return result_df

```
## 13.2 一阶自回归

用过去值来预测当前值，一阶自回归（AR(1)）
$$y_t = \beta_0+\beta_1 y_{t-1}+\epsilon_t \qquad (t=2,\cdots,n) \tag{13.6}$$
- 扰动项 $\epsilon_t$ 为白噪声
- 扰动项 $\epsilon_t$ 无自相关，意味着任意不同期的扰动项协方差为0，是球形扰动项
- OLS估计是一致的，但损失第一个数据
- 可使用MLE，但需加速扰动项服从正态分布

### Python实现
#### 使用OLS回归
```python
data2012 = data[data.index<2013].dropna()
mod = sm.OLS(endog=data2012['dlny'],
             exog=sm.add_constant(data2012['dlny'].shift(1)),
             missing='drop') # 缺失值直接drop
res = mod.fit(cov_type='HC1', use_t=True)
print(res.summary())

```
#### 使用MLE
```python
from statsmodels.tsa.ar_model import AutoReg

mod_mle = AutoReg(data2012['dlny'], lags=1)
res_mle = mod_mle.fit(cov_type='HC1',use_t=True)
print(res_mle.summary())
```
#### `predict()`的不同参数
```python
from math import exp
# 预测值

a = res.predict([1,data.loc[2013,'dlny']])
# OLS模型回归后的预测：
## - 参数是对应的 const + 其他自变量的值

b = res_mle.predict(len(data['lny']),len(data['lny']))
# AutoReg模型回归后的预测：
## - 参数是start, end

resid = exp(a + data.loc[2012,'lny']) - data.loc[2013,'y']
resid
```
## 13.3 高阶自回归

高阶自回归（AR(p)）:
$$y_t = \beta_0+\beta_1 y_{t-1}+\cdots+\beta_p y_{t-p}+\epsilon_t  \tag{13.6}$$
但通常我们并不知道p是多少，需要估计出p是多少。有三个方法：
1. 由大到小的序贯t规则：
	- 设一个最大滞后值，看最大滞后期的系数是否显著，不显著就往小了进行估计，直至显著。
2. 使用信息准则：
	- 使AIC和BIC最小的p，AIC在大样本中会高估，取两者滞后阶数的大者
3. 检验模型残差的自相关性(Q检验)，如存在，继续扩大。

```python
def estimate_p(data, col, lags):
    '''estimate_p 用于估计AR模型的p值
        集中显示k阶ar模型的p值,AIC,BIC
    Arguments:
        data -- dataframe: 包含时间序列数据的
        col  -- str:       时间序列的列名
        lags -- int:       假设的AR模型最大阶数
    returns:
        df -- dataframe: 包含lags阶AR模型的p值,AIC,BIC
                         - 每阶只显示最大阶数的值
    '''

    def _AR_p(data, col, lag):
        endog = data[col]
        exog_var =[]
        for i in range(1,lag+1):
            data[f'{col}_l{i}']=data['dlny'].shift(i)
            exog_var.append(f'{col}_l{i}')    
        exog = sm.add_constant(data[exog_var])  
        res=sm.OLS(endog=endog, exog=exog, missing='drop').fit(cov_type='HC1')
        return res.params.index[-1], res.nobs, res.pvalues[-1], res.aic, res.bic

    df = pd.DataFrame({'index':['nobs', 'p-value', 'AIC', 'BIC']})
    df.set_index('index', inplace=True)
    for i in range(lags):
        _ = _AR_p(data, col, i+1)
        df[_[0]] = _[1:]
        
    df =  df.T
    min_ = df[['AIC', 'BIC']].min()
    for col,row in df[['p-value','AIC', 'BIC']].iterrows():
        if row['AIC'] == min_['AIC']:
            df.loc[col, 'AIC'] = f"{row['AIC']:.4f}[min]"
        if row['BIC'] == min_['BIC']:
            df.loc[col, 'BIC'] = f"{row['BIC']:.4f}[min]"
        if row['p-value'] > 0.05:
            df.loc[col, 'p-value'] = f"{row['p-value']:.5f}[>0.05]"

    return df
```

结果：
```python
data = data[data.index< 2013]
df = estimate_p(data, 'dlny', 3)
df
```

|index|nobs|p-value|AIC|BIC|
|---|---|---|---|---|
|dlny_l1|33.0|0.000313|-157.9223[min]|-154.9293[min]|
|dlny_l2|32.0|0.00336|-157.398728|-153.00152|
|dlny_l3|31.0|0.90479[>0.05]|-153.816216|-148.080267|
综合考虑，取2最合适。
## 13.4 自回归分布滞后模型
autoregressive distributed lag model 

在自回归模型中，引入其他解释变量，$ARDL(p,q)$
$$y_t = \beta_0 +\beta_1 y_{t-1}+\cdots+\beta_p y_{t-p}+\gamma_1 x_{t-1}+\cdots+\gamma_q x_{t-q}+\epsilon_t \tag{13.11}$$
- p为y的滞后阶数
- q为x的滞后阶数
- 还可引入更多的解释变量，如z的r阶滞后

对于（p,q）的选择，可使用：
- 信息准则
- 序贯检验
### 长期效应 or 长期乘数
- 因y和x均为平稳序列，各滞后期序列的均值均为 $y^*$ 和 $x^*$。对（13.11）两边同时求期望，整理后可得：
- $$\frac{dy^*}{dx^*}=\frac{\gamma_1+\cdots+\gamma_q}{1-\beta_1-\cdots-\beta_p}$$
```python
from statsmodels.tsa.ardl.model import ARDL

data_ = pd.read_stata('../2_Data/Data-2e/border.dta')
endog = data_['border']
  
exog = data_[['drought','diff','age','rival','wall','unified']]
exog_lags = {
             'drought':[1], # 通过传入字典设置第4个参数
             'diff':0,      # key: 解释变量列名
             'age':0,       # value: 滞后期数
             'rival':0,     #     - int 最大滞后期 及 之前的每期都有
             'wall':0,
             'unified':0
             }
mod_ardl = ARDL(endog,2, exog, exog_lags)
res_ardl = mod_ardl.fit()
print(res_ardl.summary())
```

长期乘数
```python
res_ardl.params
lrm_drought  = res_ardl.params['drought.L1']/(1-res_ardl.params['border.L1']-res_ardl.params['border.L2'])
lrm_drought
```
## 13.5 误差修正模型
Error Correation Model

考虑ARDL(1,1)模型：
$$y_t = \beta_0 + \beta_1 y_{t-1}+\gamma_1 x_{t-1} + \epsilon_t \tag{13.16}$$
 假设存在如下长期均衡关系：
 $$y = \phi + \theta x \tag{13.17}$$
 可通过对（13.16）两边求期望，求得长期乘数。
 再在（13.16）两边同时减去 $y_{t-1}$，得到$$\Delta y_t=(\beta_1 -1)(y_{t-1} - \phi-\theta x_{t-1}) + \epsilon_t$$
 - 这就是误差修正的形式。
 - $(\beta_1 -1)(y_{t-1} - \phi-\theta x_{t-1})$ 是误差修正项
## 13.6 移动平均与ARMA模型
### MA(q)：
$$y_t=\mu + \epsilon_t +\theta_1 \epsilon_{t-1}+\cdots+\theta_q \epsilon_{t-q} $$
### ARMA(p,q):
$$y_t=\beta_0 + \beta_1 y_{t-1}+\cdots+ \beta_p y_{t-p}+\epsilon_t +\theta_1 \epsilon_{t-1}+\cdots+\theta_q \epsilon_{t-q} $$
- 其中 {$\epsilon_t$}为白噪声
## 13.7 脉冲响应函数
Impulse Response Function

- 【 #命题 】 假设$|\beta_1| < 0$，则AR(1)就是MA($\infty$)。

对AR（1）无限展开可得：
$$y_t = \frac{\beta_0}{1-\beta_1}+\beta_1\epsilon_{t-1}+\beta_1^2\epsilon_{t-2}+\cdots \tag{13.27}$$
调整时间下标 $\{t-j\}$转换为 $\{t\}$，对$\epsilon_t$求偏导:
$$IRF(j) \equiv \frac{\partial y_{t+j}}{\partial \epsilon_t} = \beta_1^j$$
- 称为动态乘子（Dynamic Multiplier）
- 将其视为时间间隔j的函数，则称为<span style="color:#00b0f0">脉冲响应函数</span>（IRF）
- 对$(j,\frac{\partial y_{t+j}}{\partial \epsilon_t})$ 作图，可得<span style="color:#00b0f0">脉冲响应图</span>。
## 13.8 向量自回归过程
vector autoregression

同时关心多个经济变量的预测
- 用单个变量时间序列的方法对每个变量分别做预测
- 将这些变了放在一起，作为一个系统来预测，使预测相互自洽

### VAR(p)
向量自回归：
$$
\left \{ 
\begin{array}{c}
y_{1t} = \beta_{10}+\beta_{11} y_{1,t-1}+\cdots+ \beta_{1,t-p} + \gamma_{11}y_{2,t-1}+\cdots+ \gamma_{2,t-p} +\epsilon_{1t}\\ 
y_{1t} = \beta_{20}+\beta_{21} y_{2,t-1}+\cdots+ \beta_{2,t-p} + \gamma_{21}y_{2,t-1}+\cdots+ \gamma_{2,t-p} +\epsilon_{2t}
\end{array}
\right.
$$
写出矩阵形式：
$$\mathbf y_t = \mathbf {\Gamma_0 + \Gamma_1y_{t-1}+\cdots+\Gamma_p y_{t-p} + \epsilon_t}$$
- $\{\epsilon_t\}$ ：向量白噪声过程/新息过程（innovation process）

### 1.滞后阶数的选择
- 信息准则
- 最后一阶系数的显著性
- VAR模型的残差是否为白噪声，是否为自相关。
	- 存在，继续向更高阶滞后项推。

### 2.VAR变量个数的选择
参数数量呈指数上升，通常变量不多 

## 13.9 VAR的脉冲响应函数

同AR模型的IRF，但是变成矩阵。

OIRF（orthogonalized impluse response function）
从扰动项中分离出相关正交的部分，记为，新扰动项的个分量正交，且方差均被标准化为1。
## 13.10 格兰杰因果检验
Granger causality test

如果x是y的因，但y不是x的因，则x的过去值可帮助预测y的未来值，反之不成立。
- 原因必然发生于结果之前
- 原因包含有关结果的独特信息

模型：
$$y_t = \gamma + \sum_{m=1}^p\alpha_m y_{t-m}+ \sum_{m=1}^p\beta_m x_{t-m} + \epsilon_t$$

原假设：$H_0:\beta_1= \cdots =\beta_p=0$
- 拒绝：x是y的格兰杰因
- 反向检测y是x的格兰杰因
实际操作中构建二元VAR系统。
- 非真正意义上的因果关系
- 顶多是因果关系的必要条件，可能由第三个变量引起
- 仅适用于平稳序列，或者有协整的单位根过程。

## 13.11 VAR的Stata命令及实例
![[VAR流程.svg]]


## 13.12 时间趋势项


## 13.13 季节调整


## 13.14 日期数据的导入




## 本章小结

## 习题

